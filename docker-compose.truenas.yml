# Tele-Agent Docker Compose for TrueNAS Scale
# 
# Usage:
# 1. Create a dataset on TrueNAS for persistent data (e.g., /mnt/pool/apps/tele-agent)
# 2. Create subdirectories: data/, personality/, logs/
# 3. Copy your personality files to personality/: SOUL.md, IDENTITY.md, USER.md, TOOLS.md
# 4. Create .env file with your secrets (see below)
# 5. Deploy via TrueNAS Apps > Custom App or Portainer
#
# Required .env variables:
#   TELEGRAM_BOT_TOKEN=your_bot_token
#   TELEGRAM_ADMIN_ID=your_telegram_user_id
#   ANTHROPIC_API_KEY=your_key (or GEMINI_API_KEY, or use Ollama)
#

version: "3.8"

services:
  tele-agent:
    # Update with your actual GitHub username/repo
    image: ghcr.io/GITHUB_USERNAME/tele-agent:latest
    container_name: tele-agent
    restart: unless-stopped
    
    environment:
      # Telegram (required)
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_ADMIN_ID=${TELEGRAM_ADMIN_ID}
      
      # LLM Provider - Ollama (for local TrueNAS deployment)
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3}
      - OLLAMA_EMBED_MODEL=${OLLAMA_EMBED_MODEL:-nomic-embed-text}
      
      # LLM Provider - Gemini (optional)
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-1.5-flash}
      
      # LLM Provider - Anthropic (optional)
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-3-haiku-20240307}
      
      # Default provider
      - DEFAULT_LLM_PROVIDER=${DEFAULT_LLM_PROVIDER:-ollama}
      
      # Personality files location (mounted)
      - SOUL_FILE=/app/personality/SOUL.md
      - IDENTITY_FILE=/app/personality/IDENTITY.md
      - USER_FILE=/app/personality/USER.md
      - TOOLS_FILE=/app/personality/TOOLS.md
    
    volumes:
      # Persistent data (ChromaDB, conversation history, state)
      - /mnt/pool/apps/tele-agent/data:/app/data
      
      # Personality files (your AI's identity - customize these!)
      - /mnt/pool/apps/tele-agent/personality:/app/personality:ro
      
      # Skills directory (optional - for custom skills)
      - /mnt/pool/apps/tele-agent/skills:/app/skills:ro
      
      # Logs
      - /mnt/pool/apps/tele-agent/logs:/app/logs
    
    # For accessing Ollama on the TrueNAS host
    extra_hosts:
      - "host.docker.internal:host-gateway"
    
    # Optional: limit resources
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

    # Health check
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
